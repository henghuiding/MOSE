<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <link rel="author" href="https://henghuiding.github.io/MOSE">
  <title>MOSE: Complex Video Object Segmentation Dataset</title>
  <meta name="description" content="MOSE: Complex Video Object Segmentation Dataset">
  <meta name="keywords" content="MOSE; Complex Video Object Segmentation Dataset; MOSE: Complex Video Object Segmentation Dataset; MOSE Dataset; VOS Dataset; Video Object Segmentation; VOS; Video Segmentation; Video Instance Segmentation; Henghui Ding; Nanyang Technological University; Computer Vision">
  
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="MOSE: Complex Video Object Segmentation Dataset">
  <meta property="og:title" content="MOSE: Complex Video Object Segmentation Dataset"/>
  <meta property="og:description" content="MOSE: Complex Video Object Segmentation Dataset"/>
  <meta property="og:url" content="https://henghuiding.github.io/MOSE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="MOSE: Complex Video Object Segmentation Dataset">
  <meta name="twitter:description" content="MOSE: Complex Video Object Segmentation Dataset">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="MOSE; Complex Video Object Segmentation Dataset; MOSE: Complex Video Object Segmentation Dataset; MOSE Dataset; VOS Dataset; Video Object Segmentation; VOS; Video Segmentation; Video Instance Segmentation; Henghui Ding; Nanyang Technological University; Computer Vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  
  <link rel="icon" type="image/x-icon" href="static/favicon_io/favicon.ico">
  <link rel="apple-touch-icon" sizes="180x180" href="static/favicon_io/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="static/favicon_io/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="static/favicon_io/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <meta name="google-site-verification" content="RHqlM-yRssUYgbykhtd0uguPnqkhTvwJw-aLE04B4KQ" />
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://henghuiding.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          Challenges
        </a>
        <div class="navbar-dropdown">
           <a class="navbar-item" href="https://henghuiding.github.io/MOSE/ChallengeCVPR2024">
            1st MOSE Challenge on CVPR 2024
          </a>
          <a class="navbar-item" href="https://henghuiding.github.io/MeViS/ChallengeCVPR2024">
            1st MeViS Challenge on CVPR 2024
          </a>
          <a class="navbar-item" href="https://henghuiding.github.io/MOSE">
            MOSE Dataset Page
          </a>
          <a class="navbar-item" href="https://henghuiding.github.io/MeViS">
            MeViS Dataset Page
          </a>
          <a class="navbar-item" href="https://henghuiding.github.io/GRES">
            GRES Dataset Page
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MOSE: A New Dataset for Video Object Segmentation in Complex Scenes</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://henghuiding.github.io/" target="_blank">Henghui Ding</a><sup>1</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="">Chang Liu</a><sup>1</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="https://heshuting555.github.io/" target="_blank">Shuting He</a><sup>1</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="https://personal.ntu.edu.sg/exdjiang/" target="_blank">Xudong Jiang</a><sup>1</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="https://torrvision.com/" target="_blank">Philip H.S. Torr</a><sup>2</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="https://songbai.site/" target="_blank">Song Bai</a><sup>3</sup></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>Nanyang Technological University&nbsp;&nbsp;&nbsp;&nbsp;
                      <sup>2</sup>University of Oxford&nbsp;&nbsp;&nbsp;&nbsp;
                      <sup>3</sup>ByteDance&nbsp;&nbsp;&nbsp;&nbsp;</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
<!--                       <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span> -->
           <!--            </a>
                    </span> -->

                    <span class="link-block">
                      <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_MOSE_A_New_Dataset_for_Video_Object_Segmentation_in_Complex_ICCV_2023_paper.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>ICCV'23 PDF</span>
                    </a>
                  </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="https://github.com/henghuiding/MOSE-api" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
<!--                       <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span> -->
                      <span>üî•Dataset</span>
                    </a>
                  </span>
                  <span class="link-block">
                      <a href="https://codalab.lisn.upsaclay.fr/competitions/10703" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
<!--                       <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span> -->
                      <span>üî•Eval Server</span>
                    </a>
                  </span>

                  <!-- Github link -->
<!--                   <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2302.01872" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <span class="link-block">
                      <a href="ChallengeCVPR2024.html" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
<!--                       <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span> -->
                      <span>Challenge/Workshop</span>
                    </a>
                  </span>


            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <center><img src="static/DemoImages/teaser.png" border="0" width="100%"></center>
      <!-- <h2 class="subtitle has-text-centered"> -->
        <div align="center"><p style="text-align:justify; text-justify:inter-ideograph;width:100%">Figure 1. Examples of video clips from the co<b><font color="#FF6403">M</font></b>plex video <b><font color="#FF6403">O</font></b>bject <b><font color="#FF6403">SE</font></b>gmentation (<b><font color="#FF6403">MOSE</font></b>) dataset. The selected target objects are masked in <font color="#FF6403">orange ‚ñá</font>. The most notable feature of MOSE is complex scenes, including the disappearance-reappearance of objects, inconspicuous small objects, heavy occlusions, crowded environments, <i>etc</i>. The goal of MOSE dataset is to provide a platform that promotes the development of more comprehensive and robust video object segmentation algorithms.</p></div><br> 

        <h2 class="title">News</h2>
                <HR color=#F0F0F0 width="97%" SIZE=1>
                <div class="news" style="overflow:auto; height:200px; Width:99%;padding-top: 6px;">
                <ul>
                <li>[07, 2023]&nbsp;&nbsp;&nbsp; <font color="#FF6403">MOSE Dataset</font> is accepted to ICCV 2023.</li>
                <li>[02, 2023]&nbsp;&nbsp;&nbsp; <font color="#FF6403">MOSE Dataset</font> is released. <a href="https://codalab.lisn.upsaclay.fr/competitions/10703" target="_blank">Evaluation server</a> is online.</li>
                </ul>
      <!-- </h2> -->
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p style="text-align:justify; text-justify:inter-ideograph;">
      Video object segmentation (VOS) aims at segmenting a particular object throughout the entire video clip sequence. The state-of-the-art VOS methods have achieved excellent performance (<i>e.g.</i>, <b>90+%</b> <i>J&F</i>) on existing datasets. However, since the target objects in these existing datasets are usually relatively salient, dominant, and isolated, VOS under complex scenes has rarely been studied. To revisit VOS and make it more applicable in the real world, we collect a new VOS dataset called co<b>M</b>plex video <b>O</b>bject <b>SE</b>gmentation (<b>MOSE</b>) to study the tracking and segmenting objects in complex environments. MOSE contains <b>2,149</b> video clips and <b>5,200</b> objects from <b>36</b> categories, with <b>431,725</b> high-quality object segmentation masks. The most notable feature of MOSE dataset is complex scenes with crowded and occluded objects. The target objects in the videos are commonly occluded by others and disappear in some frames. To analyze the proposed MOSE dataset, we benchmark 18 existing VOS methods under 4 different settings on the proposed MOSE dataset and conduct comprehensive comparisons. The experiments show that current VOS algorithms cannot well perceive objects in complex scenes. For example, under the semi-supervised VOS setting, the highest <i>J&F</i> by existing state-of-the-art VOS methods is only <b>59.4%</b> on MOSE, much lower than their <b>‚àº90%</b> <i>J&F</i> performance on DAVIS. The results reveal that although excellent performance has been achieved on existing benchmarks, there are unresolved challenges under complex scenes and more efforts are desired to explore these challenges in the future.
    </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

    </div>
    <section class="section" id="Visualization">
    <div class="container is-max-desktop content">
      <h2 class="title">Visualization</h2>
     <center>
        <img src="static/DemoImages/webp/0442a954.webp" alt="0442a954" width="224" height="126" />&nbsp;
        <img src="static/DemoImages/webp/d321dde4.webp" alt="d321dde4" width="224" height="126" />&nbsp;
        <img src="static/DemoImages/webp/02221fb0.webp" alt="02221fb0" width="224" height="126" />&nbsp;
        <img src="static/DemoImages/webp/bbe97d18.webp" alt="bbe97d18" width="224" height="126" />&nbsp;
        

        <img src="static/DemoImages/webp/002b4dce.webp" alt="002b4dce" width="224" height="126" />&nbsp;
        <img src="static/DemoImages/webp/26ed56e6.webp" alt="26ed56e6" width="224" height="126" />&nbsp;
        <img src="static/DemoImages/webp/c791ddbb.webp" alt="c791ddbb" width="224" height="126" />&nbsp;      
        <img src="static/DemoImages/webp/e5e9eb29.webp" alt="e5e9eb29" width="224" height="126" />&nbsp;

      </center>
    </div>
</section>

<section class="section" id="DatasetStatistics">
     <div class="container is-max-desktop content">
      <h2 class="title">Dataset Statistics</h2>
     <center>


     <table border="0.6">
      <caption><b>TABLE 1. Scale comparison between MOSE and existing VOS datasets.</b><br><font color="#737373">‚ÄúmBOR‚Äù: mean of the Bounding-box-Occlusion
Rate. ‚ÄúDisapp. Rate‚Äù: the frequency of disappearance objects.</font></caption>
 <!-- The newly built MOSE has the longest video duration and largest objects and annotations. More important, the most notable feature of MOSE is that it contains lots of crowds, occlusions, and disappearance-reappearance objects, which provide more complex scenarios for VOS. -->
  <tbody>
    <tr>
        <th align="right" bgcolor="BBBBBB">Dataset</th>
        <th align="center" bgcolor="BBBBBB">Year</th>
        <th align="center" bgcolor="BBBBBB">Videos</th>
        <th align="center" bgcolor="BBBBBB">Categories</th>
        <th align="center" bgcolor="BBBBBB">Objects</th>
        <th align="center" bgcolor="BBBBBB">Annotations</th>
        <th align="center" bgcolor="BBBBBB">Duration (min)</th>
        <th align="center" bgcolor="BBBBBB">mBOR</th>
        <th align="center" bgcolor="BBBBBB">Disapp. Rate</th>
    </tr>
    <tr>
      <td align="right"><a href="https://data.vision.ee.ethz.ch/cvl/youtube-objects/" target="_blank">YouTube-Objects</a></td>
      <td align="center">2012</td>
      <td align="center">96</td>
      <td align="center">10</td>
      <td align="center">96</td>
      <td align="center">1,692</td>
      <td align="center">9.01</td>
      <td align="center">-</td>
      <td align="center">-</td>
    </tr>
    <tr>
      <td align="right" bgcolor="ECECEC"><a href="https://web.engr.oregonstate.edu/~lif/SegTrack2/dataset.html" target="_blank">SegTrack-v2</a></td>
      <td align="center" bgcolor="ECECEC">2013</td>
      <td align="center" bgcolor="ECECEC">14</td>
      <td align="center" bgcolor="ECECEC">11</td>
      <td align="center" bgcolor="ECECEC">24</td>
      <td align="center" bgcolor="ECECEC">1,475</td>
      <td align="center" bgcolor="ECECEC">0.69</td>
      <td align="center" bgcolor="ECECEC">0.12</td>
      <td align="center" bgcolor="ECECEC">8.3%</td>
    </tr>
    <tr>
      <td align="right"><a href="https://lmb.informatik.uni-freiburg.de/resources/datasets/" target="_blank">FBMS</a></td>
      <td align="center">2014</td>
      <td align="center">59</td>
      <td align="center">16</td>
      <td align="center">139</td>
      <td align="center">1,465</td>
      <td align="center">7.70</td>
      <td align="center">0.01</td>
      <td align="center">11.2%</td>
    </tr>
    <tr>
      <td align="right" bgcolor="ECECEC"><a href="https://github.com/sduirc/JumpCut" target="_blank">JumpCut</a></a></td>
      <td align="center" bgcolor="ECECEC">2015</td>
      <td align="center" bgcolor="ECECEC">22</td>
      <td align="center" bgcolor="ECECEC">14</td>
      <td align="center" bgcolor="ECECEC">22</td>
      <td align="center" bgcolor="ECECEC">6,331</td>
      <td align="center" bgcolor="ECECEC">3.52</td>
      <td align="center" bgcolor="ECECEC">0</td>
      <td align="center" bgcolor="ECECEC">0%</td>
    </tr>    
    <tr>
      <td align="right"><a href="https://davischallenge.org/" target="_blank">DAVIS-2016</td>
      <td align="center">2016</td>
      <td align="center">50</td>
      <td align="center">-</td>
      <td align="center">50</td>
      <td align="center">3,440</td>
      <td align="center">2.28</td>
      <td align="center">-</td>
      <td align="center">-</td>
    </tr>
    <tr>
      <td align="right" bgcolor="ECECEC"><a href="https://davischallenge.org/" target="_blank">DAVIS-2017</a></td>
      <td align="center" bgcolor="ECECEC">2017</td>
      <td align="center" bgcolor="ECECEC">90</td>
      <td align="center" bgcolor="ECECEC">-</td>
      <td align="center" bgcolor="ECECEC">205</td>
      <td align="center" bgcolor="ECECEC">13,543</td>
      <td align="center" bgcolor="ECECEC">5.17</td>
      <td align="center" bgcolor="ECECEC">0.03</td>
      <td align="center" bgcolor="ECECEC">16.1%</td>
    </tr>
    <tr>
      <td align="right"><a href="https://youtube-vos.org/" target="_blank">YouTube-VOS</a></td>
      <td align="center">2018</td>
      <td align="center">4,453</td>
      <td align="center">94</td>
      <td align="center">7,755</td>
      <td align="center">197,272</td>
      <td align="center">334.81</td>
      <td align="center">0.05</td>
      <td align="center">13.0%</td>
    </tr>
    <tr>
      <td align="right" bgcolor="E5E5E5"><b>MOSE (ours)</b></td>
      <td align="center" bgcolor="E5E5E5">2023</td>
      <td align="center" bgcolor="E5E5E5">2,149</td>
      <td align="center" bgcolor="E5E5E5">36</td>
      <td align="center" bgcolor="E5E5E5">5,200</td>
      <td align="center" bgcolor="E5E5E5">431,725</td>
      <td align="center" bgcolor="E5E5E5">443.62</td>
      <td align="center" bgcolor="E5E5E5">0.23</td>
      <td align="center" bgcolor="E5E5E5">41.5%</td>
    </tr>
  </tbody>
  <colgroup>
    <col>
    <col>
    <col>
    <col>
    <col>
    <col>
    <col>
    <col>
    <col>
  </colgroup>
</table>

 </center>
  </div>
</section>

<section class="section" id="Experiments">
  <div class="container is-max-desktop content">
  <h2 class="title">Experiments</h2>
    <!-- <center> -->
     We benchmark the state-of-the-art methods to the best of our knowledge, please see the <a href="https://arxiv.org/abs/2302.01872" target="_blank">Dataset Report</a> for details. If your method is more powerful, please feel free to contract us for benchmark evaluation, we will update the results.<br><br>

     <center><caption><b>TABLE 2. Benchmark results of semi-supervised (one-shot) VOS.</b></caption></center>
     <center><img src="static/DemoImages/one-shot-results.png" border="0" width="90%"></center>

    <!-- </center> -->
    </div>
</section>

<!-- End image carousel -->
<section class="section" id="Downloads">
  <div class="container is-max-desktop content">
  <h2 class="title">Downloads</h2>
    <center>
      <ul>
        <li class="grid">
          <div class="griditem">
        <a href="https://arxiv.org/abs/2302.01872" target="_blank" class="imageLink"><img src="static/DemoImages/MOSE.png"></a><br><a href="https://arxiv.org/abs/2302.01872" class="imageLink">Technical Report</a>
        </div>
          </li>
          <!-- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -->

        <li class="mygrid">
          <div class="mygriditem">
        <a href="https://github.com/henghuiding/MOSE-api" target="_blank" class="imageLink"><img src="static/DemoImages/dataset.png"></a><br><a href="https://github.com/henghuiding/MOSE-api" target="_blank">üî•Dataset (ready now!)</a>
        </div>
          </li>
          <!-- &nbsp;&nbsp;&nbsp;&nbsp; -->

        <!-- <li li class="mygrid">
          <div class="mygriditem">
        <a href="" target="_blank" class="imageLink"><img src="static/DemoImages/codalab.png"></a><br><a href="https:" target="_blank">Online Evaluation (Coming soon)</a>
        </div>
          </li> -->

        </ul><br><br>
      
    </center>
    The dataset is avalibale on <a href="https://entuedu-my.sharepoint.com/:f:/g/personal/liuc0058_e_ntu_edu_sg/EjXSfDF7QEZApAVpFJ5rfdABkHCf0k2Va6VDfUy7rpabNw?e=9BVkrz" target="_blank">OneDrive</a>, <a href="https://drive.google.com/drive/folders/1vChKHzbboP1k6wd6t95guxxURW3nIXBe?usp=sharing" target="_blank">Google Drive</a>, and <a href="https://pan.baidu.com/s/116p3tQsUqObem8G8FOJ7cA" target="_blank">Baidu WangPan</a> (Access Code: MOSE), please kindly refer to <a href="https://github.com/henghuiding/MOSE-api" target="_blank"><b>MOSE-api</b></a> for more details.
    <pre><code><b>üöÄ Download the dataset using <a href="https://pypi.org/project/gdown/" target="_blank">gdown</a> command:</b>
üì¶ train.tar.gz 20.5 GB
  gdown https://drive.google.com/uc\?id\=ID_removed_to_avoid_overaccesses_get_it_by_yourself
üì¶ valid.tar.gz 3.61 GB
  gdown https://drive.google.com/uc\?id\=ID_removed_to_avoid_overaccesses_get_it_by_yourself</code></pre>
  <font color="#737373">Tips: gdown may be temporarily throttled by Google Drive due to excessive downloads, you may wait 24h or download from the Google Drive page with a google account. Please feel free to open an issue on <a href="https://github.com/henghuiding/MOSE-api/issues" target="_blank">MOSE-api</a>.</font>
    </div>
</section>

<section class="section" id="Downloads">
  <div class="container is-max-desktop content">
  <h2 class="title">Evaluation</h2>
    <center>
        <li li class="mygrid">
          <div class="mygriditem">
        <a href="https://codalab.lisn.upsaclay.fr/competitions/10703" target="_blank" class="imageLink"><img src="static/DemoImages/codalab.png"></a><br><a href="https://codalab.lisn.upsaclay.fr/competitions/10703" target="_blank">Online Evaluation (üî•ready now!)</a>
        </div>
        </li>
    </center><br><br>

    <font style="line-height:2;">
    ‚óè Following <a href="http://davischallenge.org/" target="_blank">DAVIS</a>, we use Region Jaccard <b><i>J</i></b>, Boundary F measure <b><i>F</i></b>, and their mean <b><i>J&F</i></b> as the evaluation metrics.<br>

    ‚óè For the validation sets, the first-frame annotations are released to indicate the objects that are considered in evaluation. <br>

    ‚óè The validation set online evaluation server is <a href="https://codalab.lisn.upsaclay.fr/competitions/10703">[here]</a> for daily evaluation. <br>

    ‚óè The test set online evaluation server will be open during the competition period only. <br>

    <!-- ‚óè <font color="#FF6403">For urgent cases before online server is ready, you could send your predictions to us and we will return the <b><i>J&F</i></b> results to you.</font> -->
    </font>
  </div>
</section>



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      Please consider to cite MOSE if it helps your research.
      <pre><code>@inproceedings{MOSE,
  title={{MOSE}: A New Dataset for Video Object Segmentation in Complex Scenes},
  author={Ding, Henghui and Liu, Chang and He, Shuting and Jiang, Xudong and Torr, Philip HS and Bai, Song},
  booktitle={ICCV},
  year={2023}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<section class="section" id="License">
  <div class="container is-max-desktop content">
  <h2 class="title">License</h2>
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"  target="_blank"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a></br>
MOSE is licensed under a <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0 License</a>. The data of MOSE is released for non-commercial research purpose only.
  <!-- </center> -->
    </div>
</section>


<a href="https://clustrmaps.com/site/1bsv6" title="Visit tracker" target="_blank"><img src="//www.clustrmaps.com/map_v2.png?d=fiu-XVyK-5sfXg64QJNSVH52ERrgMlMTVeNpayx5wr0&cl=ffffff" height="1" width="1"/ style="display:block;margin-top:5px;margin-bottom:0px;margin-left:auto;text-align:right"></a>
  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>

            <center><font size=2>¬© Henghui Ding | Last updated: 07/10/2023</font></center>
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
